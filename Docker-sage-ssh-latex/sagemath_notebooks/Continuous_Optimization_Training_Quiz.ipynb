{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4126847a",
   "metadata": {},
   "source": [
    "$\\textbf{Question1}$ \n",
    "\n",
    "The univariate function $1+x^2−x^4/4$ exhibits stationary points at $x=–\\sqrt{2}$, x=0, and $x=\\sqrt{2}$.  These are, respectively. \n",
    "\n",
    "a. a saddle point, a maximum and a minimum.\n",
    "\n",
    "b. a maximum,  a minimum, and a maximum.\n",
    "\n",
    "c. three maxima.\n",
    "\n",
    "d. a minimum, a saddle point and a maximum.\n",
    "\n",
    "e. a minimum,  a maximum, and a minimum.\n",
    "\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c2725",
   "metadata": {},
   "source": [
    "To determine the nature of the stationary points of the function $f(x) = 1 + x^2 - \\frac{x^4}{4}$, we need to examine the sign of the second derivative $f''(x)$ at each stationary point.\n",
    "\n",
    "Given $f(x) = 1 + x^2 - \\frac{x^4}{4}$, we can find the first and second derivatives as follows:\n",
    "\n",
    "$f'(x) = 2x - x^3$\n",
    "$f''(x) = 2 - 3x^2$\n",
    "\n",
    "Now let's evaluate $f''(x)$ at each stationary point:\n",
    "\n",
    "1. $x = -\\sqrt{2}$: $f''(-\\sqrt{2}) = 2 - 3(-\\sqrt{2})^2 = 2 - 3(2) = 2 - 6 = -4$\n",
    "2. $x = 0$: $f''(0) = 2 - 3(0)^2 = 2$\n",
    "3. $x = \\sqrt{2}$: $f''(\\sqrt{2}) = 2 - 3(\\sqrt{2})^2 = 2 - 3(2) = 2 - 6 = -4$\n",
    "\n",
    "From these calculations, we can determine the concavity at each point:\n",
    "\n",
    "- $x = -\\sqrt{2}$: Concave down (negative second derivative), so it's a local maximum.\n",
    "- $x = 0$: Concave up (positive second derivative), so it's a local minimum.\n",
    "- $x = \\sqrt{2}$: Concave down (negative second derivative), so it's a local maximum.\n",
    "\n",
    "So, the correct answer is:\n",
    "\n",
    "**b. a maximum, a minimum, and a maximum.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bca73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2941ed15",
   "metadata": {},
   "source": [
    "$\\textbf{Question2}$ \n",
    "\n",
    "The univariate function $x^3 + x^2 −x −1$ exhibits stationary points at x=−1 and $x=\\frac{1}{3}$. These are, respectively,\n",
    "\n",
    "a. a maximum and a minimum.\n",
    "\n",
    "b. a saddle point and a minimum.\n",
    "\n",
    "c. a minimum and a maximum.\n",
    "\n",
    "d. two saddle points.\n",
    "\n",
    "e. None of these.\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7403d",
   "metadata": {},
   "source": [
    "To determine the nature of the stationary points of the function $ f(x) = x^3 + x^2 - x - 1 $ at $ x = -1 $ and $ x = \\frac{1}{3} $, we need to analyze the behavior of the function around these points using the first and second derivative tests.\n",
    "\n",
    "1. **First Derivative Test:**\n",
    "   - At a stationary point, the first derivative is zero.\n",
    "   - $ f'(x) = 3x^2 + 2x - 1 $\n",
    "   - For $ x = -1 $, $ f'(-1) = 0 $.\n",
    "   - For $ x = \\frac{1}{3} $, $ f'\\left(\\frac{1}{3}\\right) = 0 $.\n",
    "\n",
    "2. **Second Derivative Test:**\n",
    "   - At a stationary point where the first derivative is zero, we use the second derivative to determine concavity.\n",
    "   - $ f''(x) = 6x + 2 $\n",
    "   - For $ x = -1 $, $ f''(-1) = 6(-1) + 2 = -4 $, indicating a maximum.\n",
    "   - For $ x = \\frac{1}{3} $, $ f''\\left(\\frac{1}{3}\\right) = 6\\left(\\frac{1}{3}\\right) + 2 = 4 $, indicating a minimum.\n",
    "\n",
    "So, the correct answer is:\n",
    "\n",
    "c. a minimum and a maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b171fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bea25dce",
   "metadata": {},
   "source": [
    "$\\textbf{Question3}$ \n",
    "\n",
    "The univariate function $3x^4−26x^3+78x^2−90x+2$ exhibits stationary points at x=1, x=5/2, x=3. These are respectively:\n",
    "\n",
    "a. a minimum, a maximum, and a minimum.\n",
    "b. three minima.\n",
    "c. two maxima and one minimum.\n",
    "d. two minima and one maximum.\n",
    "e. a maximum, a minimum, and a maximum.\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608eb540",
   "metadata": {},
   "source": [
    "To determine the nature of the stationary points, we need to analyze the behavior of the function around each point. We can do this by examining the sign of the derivative.\n",
    "\n",
    "Given the function $ f(x) = 3x^4 - 26x^3 + 78x^2 - 90x + 2 $, let's find its derivative $ f'(x) $ using calculus:\n",
    "\n",
    "$ f'(x) = 12x^3 - 78x^2 + 156x - 90 $\n",
    "\n",
    "Now, let's evaluate $ f'(x) $ at each stationary point:\n",
    "\n",
    "1. At $ x = 1 $:\n",
    "$ f'(1) = 12(1)^3 - 78(1)^2 + 156(1) - 90 = 12 - 78 + 156 - 90 = 0 $\n",
    "Since the derivative changes sign from negative to positive, $ x = 1 $ is a local minimum.\n",
    "\n",
    "2. At $ x = \\frac{5}{2} $:\n",
    "$ f'\\left(\\frac{5}{2}\\right) = 12\\left(\\frac{5}{2}\\right)^3 - 78\\left(\\frac{5}{2}\\right)^2 + 156\\left(\\frac{5}{2}\\right) - 90 $\n",
    "$ = 12\\left(\\frac{125}{8}\\right) - 78\\left(\\frac{25}{4}\\right) + 156\\left(\\frac{5}{2}\\right) - 90 $\n",
    "$ = 187.5 - 487.5 + 390 - 90 = 0 $\n",
    "Since the derivative changes sign from positive to negative, $ x = \\frac{5}{2} $ is a local maximum.\n",
    "\n",
    "3. At $ x = 3 $:\n",
    "$ f'(3) = 12(3)^3 - 78(3)^2 + 156(3) - 90 $\n",
    "$ = 12(27) - 78(9) + 156(3) - 90 = 0 $\n",
    "Since the derivative changes sign from negative to positive, $ x = 3 $ is a local minimum.\n",
    "\n",
    "So, the correct answer is:\n",
    "\n",
    "a. a minimum, a maximum, and a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66077d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c875bdd",
   "metadata": {},
   "source": [
    "$\\textbf{Question4}$ \n",
    "\n",
    "The function $f(x,y)=x^3+y^3−3xy$  exhibits two stationary points one at  (x,y)=(0,0) and one at (x,y)=(1,1). These are, respectively,\n",
    "\n",
    "a. two minima.\n",
    "\n",
    "b. two maxima\n",
    "\n",
    "c. a maximum and a minimum.\n",
    "\n",
    "d. a saddle point and a maximum.\n",
    "\n",
    "e. a saddle point and a minimum.\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd914186",
   "metadata": {},
   "source": [
    "To determine the nature of the stationary points of the function $ f(x, y) = x^3 + y^3 - 3xy $, we can use the second partial derivative test. \n",
    "\n",
    "1. First, find the first partial derivatives with respect to $ x $ and $ y $:\n",
    "$ \\frac{\\partial f}{\\partial x} = 3x^2 - 3y $\n",
    "$ \\frac{\\partial f}{\\partial y} = 3y^2 - 3x $\n",
    "\n",
    "2. Then, find the second partial derivatives:\n",
    "$ \\frac{\\partial^2 f}{\\partial x^2} = 6x $\n",
    "$ \\frac{\\partial^2 f}{\\partial y^2} = 6y $\n",
    "$ \\frac{\\partial^2 f}{\\partial x \\partial y} = -3 $\n",
    "\n",
    "3. Evaluate the second partial derivatives at the critical points:\n",
    "   - At (0, 0): $ \\frac{\\partial^2 f}{\\partial x^2} = 0 $, $ \\frac{\\partial^2 f}{\\partial y^2} = 0 $, $ \\frac{\\partial^2 f}{\\partial x \\partial y} = -3 $. It's inconclusive.\n",
    "   - At (1, 1): $ \\frac{\\partial^2 f}{\\partial x^2} = 6 $, $ \\frac{\\partial^2 f}{\\partial y^2} = 6 $, $ \\frac{\\partial^2 f}{\\partial x \\partial y} = -3 $. Here, $ \\frac{\\partial^2 f}{\\partial x^2} \\cdot \\frac{\\partial^2 f}{\\partial y^2} - (\\frac{\\partial^2 f}{\\partial x \\partial y})^2 > 0 $ and $ \\frac{\\partial^2 f}{\\partial x^2} > 0 $, thus it's a local minimum.\n",
    "\n",
    "So, the stationary points are:\n",
    "- (0, 0): Indeterminate\n",
    "- (1, 1): Local minimum\n",
    "\n",
    "Hence, the correct answer is option:\n",
    "c. a maximum and a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8d8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6caf0937",
   "metadata": {},
   "source": [
    "$\\textbf{Question5}$ \n",
    "\n",
    "At a certain point (x0,y0,z0) all the partial derivatives ∂f/∂x, ∂f/∂y, ∂f/∂z of a given three variable function f(x,y,z) are zero. The point is:\n",
    "\n",
    "a. A local minimum.\n",
    "\n",
    "b. A local maximum.\n",
    "\n",
    "c. Saddle point.\n",
    "\n",
    "d. Information provided is insufficient.\n",
    "\n",
    "e. A global minimum.\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe147ca",
   "metadata": {},
   "source": [
    "The given information suggests that the point (x0, y0, z0) is a critical point, where all partial derivatives of the function $ f(x, y, z) $ are zero. However, this information alone doesn't determine the nature of the critical point. To determine whether it's a local minimum, maximum, saddle point, or something else, we need more information, specifically about the second partial derivatives or higher.\n",
    "\n",
    "For example, if the second partial derivatives at the point satisfy the second derivative test:\n",
    "\n",
    "1. If the second derivative test shows that the second derivative with respect to x, y, and z are all positive at the point, then it is a local minimum.\n",
    "2. If the second derivative test shows that the second derivative with respect to x, y, and z are all negative at the point, then it is a local maximum.\n",
    "3. If the second derivative test shows that the second derivative with respect to x and y have opposite signs, or the second derivative with respect to x, y, or z is zero, then it is a saddle point.\n",
    "4. If the second derivative test is inconclusive, then further analysis is needed.\n",
    "\n",
    "Without the second derivative information, we cannot definitively determine the nature of the critical point. So, the correct answer is:\n",
    "\n",
    "d. Information provided is insufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606f265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9626c5",
   "metadata": {},
   "source": [
    "$\\textbf{Question6}$ \n",
    "\n",
    "\n",
    "We consider the multivariate function $f(x,y)=1/3(x^3−y^3)−(x−y)$.  \n",
    "\n",
    "It exhibits:\n",
    "\n",
    "a. three minima and one saddle point\n",
    "\n",
    "b. three maxima and one saddle point\n",
    "\n",
    "c. none of these\n",
    "\n",
    "d. one minimum, one maximum and two saddle points\n",
    "\n",
    "e. two minima and two maxima\n",
    "\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2bd1bd",
   "metadata": {},
   "source": [
    "To determine the critical points of the function $ f(x, y) = \\frac{1}{3}(x^3 - y^3) - (x - y) $, we first find the partial derivatives with respect to $ x $ and $ y $:\n",
    "\n",
    "$ \\frac{\\partial f}{\\partial x} = x^2 - 1 $\n",
    "$ \\frac{\\partial f}{\\partial y} = -y^2 + 1 $\n",
    "\n",
    "Setting these partial derivatives to zero to find the critical points:\n",
    "\n",
    "$ x^2 - 1 = 0 \\Rightarrow x = \\pm 1 $\n",
    "$ -y^2 + 1 = 0 \\Rightarrow y = \\pm 1 $\n",
    "\n",
    "So, the critical points are $ (1, 1) $, $ (-1, -1) $, $ (1, -1) $, and $ (-1, 1) $.\n",
    "\n",
    "To determine the nature of these critical points, we can use the second partial derivative test or the Hessian matrix. Calculating the second partial derivatives:\n",
    "\n",
    "$ \\frac{\\partial^2 f}{\\partial x^2} = 2x $\n",
    "$ \\frac{\\partial^2 f}{\\partial y^2} = -2y $\n",
    "$ \\frac{\\partial^2 f}{\\partial x \\partial y} = 0 $\n",
    "\n",
    "Now, evaluating these second partial derivatives at the critical points:\n",
    "\n",
    "At $ (1, 1) $:\n",
    "$ \\frac{\\partial^2 f}{\\partial x^2} = 2(1) = 2 $ (positive)\n",
    "$ \\frac{\\partial^2 f}{\\partial y^2} = -2(1) = -2 $ (negative)\n",
    "So, it's a saddle point.\n",
    "\n",
    "At $ (-1, -1) $:\n",
    "$ \\frac{\\partial^2 f}{\\partial x^2} = 2(-1) = -2 $ (negative)\n",
    "$ \\frac{\\partial^2 f}{\\partial y^2} = -2(-1) = 2 $ (positive)\n",
    "So, it's a saddle point.\n",
    "\n",
    "At $ (1, -1) $:\n",
    "$ \\frac{\\partial^2 f}{\\partial x^2} = 2(1) = 2 $ (positive)\n",
    "$ \\frac{\\partial^2 f}{\\partial y^2} = -2(-1) = 2 $ (positive)\n",
    "So, it's a local minimum.\n",
    "\n",
    "At $ (-1, 1) $:\n",
    "$ \\frac{\\partial^2 f}{\\partial x^2} = 2(-1) = -2 $ (negative)\n",
    "$ \\frac{\\partial^2 f}{\\partial y^2} = -2(1) = -2 $ (negative)\n",
    "So, it's a local maximum.\n",
    "\n",
    "Hence, the function exhibits one minimum, one maximum, and two saddle points, so the correct answer is:\n",
    "\n",
    "**d. one minimum, one maximum, and two saddle points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcb4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26bc162a",
   "metadata": {},
   "source": [
    "$\\textbf{Question7}$ \n",
    "\n",
    "A multivariate function $f(x1,…,xn)$ exhibits a stationary point at (x^01,…,x^0n). Given the Hessian H=H(x^01,…,x^0n), this point is always a minimum when:\n",
    "\n",
    "a. All eigenvalues of H are positive.\n",
    "\n",
    "b. All eigenvalues of H are negative.\n",
    "\n",
    "c. trace(H)>0\n",
    "\n",
    "d. det(H)<0\n",
    "\n",
    "e. None of these.\n",
    "\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97db78",
   "metadata": {},
   "source": [
    "To determine whether the stationary point is a minimum, we can use the second derivative test. The second derivative test states that if the Hessian matrix $ H $ at the stationary point has all positive eigenvalues, then the point is a local minimum. \n",
    "\n",
    "So the correct option is:\n",
    "\n",
    "a. All eigenvalues of $ H $ are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ad84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d7c788a",
   "metadata": {},
   "source": [
    "$\\textbf{Question8}$ \n",
    "\n",
    "\n",
    "Consider the  convex function $f(x_1,x_2)=x^{2}_1+10x^{2}_2$. Which of the following choices coincides with the first gradient update $x^(1)$  having selected learning rate equal to 0.01 and initial guess $x^(0)=[0.5,0.5]^T$\n",
    "\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e6c11",
   "metadata": {},
   "source": [
    "To perform gradient descent on the function $ f(x_1, x_2) = x_1^2 + 10x_2^2 $ with a learning rate of 0.01 and an initial guess of $ x^{(0)} = [0.5, 0.5]^T $, we need to compute the gradient of the function and then update the parameters iteratively using the gradient descent update rule.\n",
    "\n",
    "The gradient of $ f $ with respect to $ x_1 $ and $ x_2 $ is:\n",
    "\n",
    "$\\nabla f(x_1, x_2) = \\begin{bmatrix} 2x_1 \\\\ 20x_2 \\end{bmatrix}$\n",
    "\n",
    "The gradient descent update rule is:\n",
    "\n",
    "$x^{(k+1)} = x^{(k)} - \\alpha \\nabla f(x^{(k)})$\n",
    "\n",
    "where $ \\alpha $ is the learning rate.\n",
    "\n",
    "Given the learning rate $ \\alpha = 0.01 $, and the initial guess $ x^{(0)} = [0.5, 0.5]^T $, the first gradient update $ x^{(1)} $ can be computed as follows:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "x_1^{(1)} & = x_1^{(0)} - \\alpha \\frac{\\partial f}{\\partial x_1} \\bigg|_{x^{(0)}} \\\\\n",
    "& = 0.5 - 0.01 \\times 2 \\times 0.5 \\\\\n",
    "& = 0.5 - 0.01 \\\\\n",
    "& = 0.49\n",
    "\\end{align*}\n",
    "$\n",
    "$\n",
    "\\begin{align*}\n",
    "x_2^{(1)} & = x_2^{(0)} - \\alpha \\frac{\\partial f}{\\partial x_2} \\bigg|_{x^{(0)}} \\\\\n",
    "& = 0.5 - 0.01 \\times 20 \\times 0.5 \\\\\n",
    "& = 0.5 - 0.1 \\\\\n",
    "& = 0.4\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "So, the first gradient update $ x^{(1)} $ is approximately $ [0.49, 0.4]^T $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc9ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aed7888",
   "metadata": {},
   "source": [
    "$\\textbf{Question9}$ \n",
    "\n",
    "Consider the function $f(x,y,z)=x^3y + e^{−z}y^2 + z^3. \n",
    "In the application of the gradient descent optimization method, we search for a minimum along the direction given by the vector:\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f4f1a",
   "metadata": {},
   "source": [
    "To apply the gradient descent optimization method to find the minimum of the function $ f(x, y, z) = x^3y + e^{-z}y^2 + z^3 $, we need to compute the gradient of the function with respect to the variables $ x $, $ y $, and $ z $, and then move in the direction opposite to the gradient.\n",
    "\n",
    "The gradient of a multivariable function is a vector that points in the direction of the steepest increase of the function, and its components are the partial derivatives of the function with respect to each variable.\n",
    "\n",
    "So, let's find the gradient $ \\nabla f(x, y, z) $:\n",
    "\n",
    "$\\nabla f(x, y, z) = \\left( \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z} \\right)$\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\frac{\\partial f}{\\partial x} = 3x^2 y$\n",
    "\n",
    "$\\frac{\\partial f}{\\partial y} = x^3 + 2e^{-z}y$\n",
    "\n",
    "$\\frac{\\partial f}{\\partial z} = -e^{-z}y^2 + 3z^2$\n",
    "\n",
    "So, the gradient vector $ \\nabla f(x, y, z) $ is:\n",
    "\n",
    "$\\nabla f(x, y, z) = \\left( 3x^2 y, x^3 + 2e^{-z}y, -e^{-z}y^2 + 3z^2 \\right)$\n",
    "\n",
    "To find the direction in which the function decreases the fastest, we move in the direction opposite to the gradient. Thus, the direction vector for gradient descent is:\n",
    "\n",
    "$-\\nabla f(x, y, z) = \\left( -3x^2 y, -x^3 - 2e^{-z}y, e^{-z}y^2 - 3z^2 \\right)$\n",
    "\n",
    "This is the direction along which we would move to minimize the function $ f(x, y, z) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a89d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be13dda3",
   "metadata": {},
   "source": [
    "$\\textbf{Question10}$ \n",
    "\n",
    "Consider the linear optimization problem defined by the objective function $f(x_1,x_2)=3x_1+2x_2$ subject to the constraints $x_1+x_2≤4$ and $2x_1+x_2≤5$. \n",
    "\n",
    "The goal is to minimize f subject to these constraints. \n",
    "\n",
    "Which of the following expressions correctly represents the Lagrangian L(x1,x2,λ1,λ2) for this problem, incorporating the Lagrange multipliers λ1 and λ2, where λi>0,i=1,2, for the respective constraints?\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26997f",
   "metadata": {},
   "source": [
    "The Lagrangian for the given linear optimization problem can be expressed as follows:\n",
    "\n",
    "$ L(x_1, x_2, \\lambda_1, \\lambda_2) = f(x_1, x_2) - \\lambda_1 (x_1 + x_2 - 4) - \\lambda_2 (2x_1 + x_2 - 5) $\n",
    "\n",
    "So, among the given choices, the correct expression for the Lagrangian would be:\n",
    "\n",
    "$ L(x_1, x_2, \\lambda_1, \\lambda_2) = 3x_1 + 2x_2 - \\lambda_1 (x_1 + x_2 - 4) - \\lambda_2 (2x_1 + x_2 - 5) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7415dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ee6c4ce",
   "metadata": {},
   "source": [
    "$\\textbf{Question11}$ \n",
    "\n",
    "Which of the following functions is/are convex? \n",
    "\n",
    "(a) $f(x)=\\ln(1+e^x)$ on R,  \n",
    "\n",
    "(b) $f(x)=\\sin(x)$ on R, \n",
    "\n",
    "(c) $f(x)=\\sqrt{1+x^2}$ on R\n",
    "\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5548dac",
   "metadata": {},
   "source": [
    "To determine whether a function is convex, we typically look at the second derivative. A function is convex on an interval if its second derivative is non-negative on that interval. Let's analyze each function:\n",
    "\n",
    "(a) $ f(x) = \\ln(1+e^x) $ on $ \\mathbb{R} $:\n",
    "\n",
    "To find the second derivative, we first find the first derivative:\n",
    "\n",
    "$ f'(x) = \\frac{1}{1 + e^x} \\cdot e^x = \\frac{e^x}{1 + e^x} $\n",
    "\n",
    "Then, we find the second derivative:\n",
    "\n",
    "$ f''(x) = \\frac{e^x \\cdot (1 + e^x) - e^x \\cdot e^x}{(1 + e^x)^2} = \\frac{e^x}{(1 + e^x)^2} $\n",
    "\n",
    "This second derivative is always positive for all $ x $ in $ \\mathbb{R} $. Thus, $ f(x) = \\ln(1+e^x) $ is convex on $ \\mathbb{R} $.\n",
    "\n",
    "(b) $ f(x) = \\sin(x) $ on $ \\mathbb{R} $:\n",
    "\n",
    "The second derivative of $ \\sin(x) $ is $ -\\sin(x) $, which is not always non-negative. Thus, $ f(x) = \\sin(x) $ is not convex on $ \\mathbb{R} $.\n",
    "\n",
    "(c) $ f(x) = \\sqrt{1+x^2} $ on $ \\mathbb{R} $:\n",
    "\n",
    "To find the second derivative, we first find the first derivative:\n",
    "\n",
    "$ f'(x) = \\frac{1}{2 \\sqrt{1 + x^2}} \\cdot 2x = \\frac{x}{\\sqrt{1 + x^2}} $\n",
    "\n",
    "Then, we find the second derivative:\n",
    "\n",
    "$ f''(x) = \\frac{(1 + x^2) - x^2/(1 + x^2)}{(1 + x^2)^{3/2}} = \\frac{1}{(1 + x^2)^{3/2}} $\n",
    "\n",
    "This second derivative is always positive for all $ x $ in $ \\mathbb{R} $. Thus, $ f(x) = \\sqrt{1+x^2} $ is convex on $ \\mathbb{R} $.\n",
    "\n",
    "So, the functions that are convex on $ \\mathbb{R} $ are (a) $ f(x) = \\ln(1+e^x) $ and (c) $ f(x) = \\sqrt{1+x^2} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f8551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aba93cd3",
   "metadata": {},
   "source": [
    "$\\textbf{Question12}$ \n",
    "\n",
    "Which of the following functions is/are convex  ? \n",
    "\n",
    "a. $f(x)=x^2$ on $R$, \n",
    "\n",
    "b. $f(x)=3x+2$ on  $R$ ,  \n",
    "\n",
    "c.  $f(x,y)=e^{−x−y}$ on $R^2$\n",
    "\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183341b",
   "metadata": {},
   "source": [
    "To determine if a function is convex, we typically check if its second derivative (or Hessian matrix, for multivariable functions) is non-negative over its domain. \n",
    "\n",
    "Let's evaluate each function:\n",
    "\n",
    "a. $f(x) = x^2$ on $\\mathbb{R}$:\n",
    "   - Second derivative: $f''(x) = 2$, which is always positive. Hence, $f(x)$ is convex on $\\mathbb{R}$.\n",
    "\n",
    "b. $f(x) = 3x + 2$ on $\\mathbb{R}$:\n",
    "   - Second derivative: $f''(x) = 0$, which is neither positive nor negative. Hence, $f(x)$ is neither convex nor concave on $\\mathbb{R}$.\n",
    "\n",
    "c. $f(x,y) = e^{-x-y}$ on $\\mathbb{R}^2$:\n",
    "   - Second partial derivatives: $f_{xx} = e^{-x-y}$, $f_{yy} = e^{-x-y}$, $f_{xy} = e^{-x-y}$.\n",
    "   - The Hessian matrix is: \n",
    "     $\n",
    "     H = \\begin{pmatrix}\n",
    "     f_{xx} & f_{xy} \\\\\n",
    "     f_{xy} & f_{yy}\n",
    "     \\end{pmatrix}\n",
    "     = \\begin{pmatrix}\n",
    "     e^{-x-y} & e^{-x-y} \\\\\n",
    "     e^{-x-y} & e^{-x-y}\n",
    "     \\end{pmatrix}\n",
    "     = e^{-x-y} \\begin{pmatrix}\n",
    "     1 & 1 \\\\\n",
    "     1 & 1\n",
    "     \\end{pmatrix}\n",
    "     $\n",
    "   - The determinant of the Hessian is $|H| = 0$, and the trace of the Hessian is the sum of its eigenvalues, which is $2e^{-x-y}$.\n",
    "   - Since the determinant is zero and the trace is positive (for $e^{-x-y} > 0$), $f(x,y)$ is neither convex nor concave on $\\mathbb{R}^2$.\n",
    "\n",
    "So, only function $f(x) = x^2$ is convex on $\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731260a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f90b219",
   "metadata": {},
   "source": [
    "$\\textbf{Question13}$ \n",
    "\n",
    "Which of the functions \n",
    "\n",
    "$f_1(overrightarrow{x})=x^2_1+4x^2_2+2x_1x_2+120$ over R2, \n",
    "\n",
    "$f_2(overrightarrow{x})=x^2_1+x^2_2+x^2_3−x_1x_2−x_2x_3+120$ over R3, \n",
    "\n",
    "is/are convex ?\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83bb0d",
   "metadata": {},
   "source": [
    "To determine whether a function is convex, we can examine its Hessian matrix. A function is convex if and only if its Hessian matrix is positive semidefinite everywhere in its domain. \n",
    "\n",
    "Let's calculate the Hessian matrices for both functions:\n",
    "\n",
    "1. For $ f_1(\\vec{x}) = x_1^2 + 4x_2^2 + 2x_1x_2 + 120 $:\n",
    "\n",
    "$\n",
    "\\text{Hessian matrix} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2 f_1}{\\partial x_1^2} & \\frac{\\partial^2 f_1}{\\partial x_1 \\partial x_2} \\\\\n",
    "\\frac{\\partial^2 f_1}{\\partial x_1 \\partial x_2} & \\frac{\\partial^2 f_1}{\\partial x_2^2}\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "2 & 2 \\\\\n",
    "2 & 8\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "2. For $ f_2(\\vec{x}) = x_1^2 + x_2^2 + x_3^2 - x_1x_2 - x_2x_3 + 120 $:\n",
    "\n",
    "$\n",
    "\\text{Hessian matrix} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2 f_2}{\\partial x_1^2} & \\frac{\\partial^2 f_2}{\\partial x_1 \\partial x_2} & \\frac{\\partial^2 f_2}{\\partial x_1 \\partial x_3} \\\\\n",
    "\\frac{\\partial^2 f_2}{\\partial x_1 \\partial x_2} & \\frac{\\partial^2 f_2}{\\partial x_2^2} & \\frac{\\partial^2 f_2}{\\partial x_2 \\partial x_3} \\\\\n",
    "\\frac{\\partial^2 f_2}{\\partial x_1 \\partial x_3} & \\frac{\\partial^2 f_2}{\\partial x_2 \\partial x_3} & \\frac{\\partial^2 f_2}{\\partial x_3^2}\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "2 & -1 & 0 \\\\\n",
    "-1 & 2 & -1 \\\\\n",
    "0 & -1 & 2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Now, we need to check the eigenvalues of these matrices. If all eigenvalues are nonnegative, then the matrix is positive semidefinite and the function is convex.\n",
    "\n",
    "For $ f_1 $, the eigenvalues are approximately $ 1.1716 $ and $ 8.8284 $, both positive. So, $ f_1 $ is convex.\n",
    "\n",
    "For $ f_2 $, the eigenvalues are approximately $ 0.1716 $, $ 1.8284 $, and $ 3 $, all positive. So, $ f_2 $ is also convex.\n",
    "\n",
    "Therefore, both $ f_1 $ and $ f_2 $ are convex functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c4fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "382f9739",
   "metadata": {},
   "source": [
    "$\\textbf{Question14}$ \n",
    "\n",
    "We want to find the minimum of the univariate function $f(x)=e^xcos(x)$ in the interval (0,π) using the Newton's method. \n",
    "\n",
    "We start from the point $x_0=frac{π}{2}$. The third point $x_2$  is:\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde55cd1",
   "metadata": {},
   "source": [
    "To find the minimum of the function $ f(x) = e^x \\cos(x) $ in the interval $ (0, \\pi) $ using Newton's method, we need to iterate using the formula:\n",
    "\n",
    "$ x_{n+1} = x_n - \\frac{f'(x_n)}{f''(x_n)} $\n",
    "\n",
    "Given that $ f(x) = e^x \\cos(x) $, we need to find $ f'(x) $ and $ f''(x) $:\n",
    "\n",
    "$ f'(x) = e^x \\cos(x) - e^x \\sin(x) $\n",
    "$ f''(x) = 2e^x \\sin(x) $\n",
    "\n",
    "Starting from $ x_0 = \\frac{\\pi}{2} $, we can iterate using Newton's method:\n",
    "\n",
    "$ x_{n+1} = x_n - \\frac{f'(x_n)}{f''(x_n)} $\n",
    "\n",
    "Let's find the first iteration:\n",
    "\n",
    "$ x_1 = \\frac{\\pi}{2} - \\frac{f'(\\frac{\\pi}{2})}{f''(\\frac{\\pi}{2})} $\n",
    "\n",
    "$ f'(\\frac{\\pi}{2}) = e^{\\frac{\\pi}{2}} \\cos(\\frac{\\pi}{2}) - e^{\\frac{\\pi}{2}} \\sin(\\frac{\\pi}{2}) = 0 - e^{\\frac{\\pi}{2}} = -\\frac{1}{2} $\n",
    "\n",
    "$ f''(\\frac{\\pi}{2}) = 2e^{\\frac{\\pi}{2}} \\sin(\\frac{\\pi}{2}) = 2e^{\\frac{\\pi}{2}} $\n",
    "\n",
    "So,\n",
    "\n",
    "$ x_1 = \\frac{\\pi}{2} - \\frac{-\\frac{1}{2}}{2e^{\\frac{\\pi}{2}}} $\n",
    "$ x_1 = \\frac{\\pi}{2} + \\frac{1}{4e^{\\frac{\\pi}{2}}} $\n",
    "\n",
    "Now, for the second iteration, $ x_1 $ will be our new $ x_0 $:\n",
    "\n",
    "$ x_2 = x_1 - \\frac{f'(x_1)}{f''(x_1)} $\n",
    "\n",
    "$ f'(x_1) = e^{x_1} \\cos(x_1) - e^{x_1} \\sin(x_1) $\n",
    "\n",
    "$ f''(x_1) = 2e^{x_1} \\sin(x_1) $\n",
    "\n",
    "Now, substitute these values and compute $ x_2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfdfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0adf0d1",
   "metadata": {},
   "source": [
    "$\\textbf{Question15}$ \n",
    "\n",
    "The dual of the LP problem: max $5x_1+6x_2−10x_3$ subject to \n",
    "\n",
    "$6x_1+3x_2+10x_3 <= 4$,\n",
    "\n",
    "$7x_1+x_2+8x_3<=100$,\n",
    "\n",
    "$4x_1+x_3≤50,x_1,x_2,x_3>=0$ is\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d08b8",
   "metadata": {},
   "source": [
    "The dual of a linear programming (LP) problem involves flipping the roles of the variables and constraints. In the primal problem, we have variables $ x_1, x_2, x_3 $ and constraints in the form of linear inequalities. To form the dual, we introduce a new variable for each constraint in the primal problem and a constraint for each variable.\n",
    "\n",
    "The primal problem is:\n",
    "\n",
    "Maximize: $ 5x_1 + 6x_2 - 10x_3 $\n",
    "\n",
    "Subject to:\n",
    "\n",
    "1. $ 6x_1 + 3x_2 + 10x_3 \\leq 4 $\n",
    "2. $ 7x_1 + x_2 + 8x_3 \\leq 100 $\n",
    "3. $ 4x_1 + x_3 \\leq 50 $\n",
    "4. $ x_1, x_2, x_3 \\geq 0 $\n",
    "\n",
    "The dual problem involves creating a new variable for each constraint and a constraint for each variable:\n",
    "\n",
    "Minimize: $ 4y_1 + 100y_2 + 50y_3 $\n",
    "\n",
    "Subject to:\n",
    "\n",
    "1. $ 6y_1 + 7y_2 + 4y_3 \\geq 5 $\n",
    "2. $ 3y_1 + y_2 + y_3 \\geq 6 $\n",
    "3. $ 10y_1 + 8y_2 \\geq -10 $\n",
    "4. $ y_1, y_2, y_3 \\geq 0 $\n",
    "\n",
    "This is the dual LP problem corresponding to the given primal LP problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777fdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9a6c9ff",
   "metadata": {},
   "source": [
    "$\\textbf{Question16}$ \n",
    "\n",
    "The function $F(x)=X^TSX/X^TX$  with \n",
    "$X^T=(x,y)∈R^2−(0,0)$ and  \n",
    "$S=\\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix}$  is not convex. \n",
    "It attains a maximum as well as a minimum value.  \n",
    "At a minimum point (x0,y0) what is the second derivative matrix H ? \n",
    "provide final result\n",
    "\n",
    "steps to follow: \n",
    "- Compute the function after substituting X and S.\n",
    "- Locate the stationary points by solving  ∇⃗ F=0.\n",
    "- Note that the stationary points could extend along lines, e.g. x=0. \n",
    "To determine whether a solution leads to a minimum or maximum, calculate the function value at this point. The smaller value corresponds to the minimum. \n",
    "- Finally, compute the Hessian at this point.\n",
    "\n",
    "\n",
    "$\\textbf{Answer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c6778",
   "metadata": {},
   "source": [
    "Let's follow the steps provided to solve the problem:\n",
    "\n",
    "1. **Compute the function after substituting X and S**:\n",
    "\n",
    "   Given: \n",
    "   $ F(x) = \\frac{X^T S X}{X^T X} $\n",
    "   \n",
    "   Substituting $ X^T = (x, y) $ and $ S = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} $, we get:\n",
    "   \n",
    "   $ F(x) = \\frac{\\begin{bmatrix} x & y \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}}{\\begin{bmatrix} x & y \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}} $\n",
    "   \n",
    "   $ = \\frac{\\begin{bmatrix} x & y \\end{bmatrix} \\begin{bmatrix} x \\\\ 2y \\end{bmatrix}}{\\begin{bmatrix} x & y \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}} $\n",
    "   \n",
    "   $ = \\frac{x^2 + 2y^2}{x^2 + y^2} $\n",
    "\n",
    "2. **Locate the stationary points by solving $ \\nabla \\vec{F} = 0 $**:\n",
    "\n",
    "   The gradient of $ F(x) $ is:\n",
    "   \n",
    "   $ \\nabla \\vec{F} = \\begin{bmatrix} \\frac{\\partial F}{\\partial x} \\\\ \\frac{\\partial F}{\\partial y} \\end{bmatrix} $\n",
    "   \n",
    "   To find stationary points, we solve $ \\nabla \\vec{F} = \\vec{0} $:\n",
    "   \n",
    "   $ \\frac{\\partial F}{\\partial x} = \\frac{2x(x^2+y^2) - 2x(x^2+2y^2)}{(x^2+y^2)^2} = 0 $\n",
    "   \n",
    "   $ \\frac{\\partial F}{\\partial y} = \\frac{4y(x^2+y^2) - 2y(x^2+2y^2)}{(x^2+y^2)^2} = 0 $\n",
    "   \n",
    "   Simplifying these expressions:\n",
    "   \n",
    "   $ 2x(x^2+y^2) - 2x(x^2+2y^2) = 0 $\n",
    "   \n",
    "   $ 4y(x^2+y^2) - 2y(x^2+2y^2) = 0 $\n",
    "   \n",
    "   After some algebraic manipulations, we find that $ x = 0 $ and $ y = 0 $ are the only stationary points.\n",
    "\n",
    "3. **Determine whether the stationary point leads to a minimum or maximum**:\n",
    "\n",
    "   To determine whether the stationary point leads to a minimum or maximum, let's consider the function value at this point:\n",
    "   \n",
    "   $ F(0,0) = \\frac{0^2 + 2(0)^2}{0^2 + 0^2} = \\frac{0}{0} $\n",
    "   \n",
    "   At this point, the function is indeterminate. We need to further analyze to determine the nature of the stationary point.\n",
    "\n",
    "4. **Compute the Hessian at this point**:\n",
    "\n",
    "   The Hessian matrix is given by:\n",
    "   \n",
    "   $ H = \\begin{bmatrix} \\frac{\\partial^2 F}{\\partial x^2} & \\frac{\\partial^2 F}{\\partial x \\partial y} \\\\ \\frac{\\partial^2 F}{\\partial y \\partial x} & \\frac{\\partial^2 F}{\\partial y^2} \\end{bmatrix} $\n",
    "   \n",
    "   To compute the second derivatives, let's find $ \\frac{\\partial^2 F}{\\partial x^2} $, $ \\frac{\\partial^2 F}{\\partial y^2} $, and $ \\frac{\\partial^2 F}{\\partial x \\partial y} $:\n",
    "\n",
    "   $ \\frac{\\partial^2 F}{\\partial x^2} = \\frac{2(x^2+y^2)^2 - 4x^2(x^2+2y^2) - 2(x^2+y^2)2x^2}{(x^2+y^2)^3} $\n",
    "\n",
    "   $ \\frac{\\partial^2 F}{\\partial y^2} = \\frac{8y^2(x^2+y^2) - 4y^2(x^2+2y^2) - 2(x^2+y^2)4y^2}{(x^2+y^2)^3} $\n",
    "\n",
    "   $ \\frac{\\partial^2 F}{\\partial x \\partial y} = \\frac{4xy(x^2+y^2) - 4xy(x^2+2y^2) - 2(x^2+y^2)2xy}{(x^2+y^2)^3} $\n",
    "\n",
    "   Substituting $ x = 0 $ and $ y = 0 $ into these expressions gives us the elements of the Hessian matrix. After evaluation, we get:\n",
    "\n",
    "   $ H = \\begin{bmatrix} 0 & 0 \\\\ 0 & \\frac{2}{x^2} \\end{bmatrix} $\n",
    "\n",
    "   Thus, the second derivative matrix $ H $ at the stationary point $ (0, 0) $ is $ \\begin{bmatrix} 0 & 0 \\\\ 0 & \\frac{2}{x^2} \\end{bmatrix} $. \n",
    "\n",
    "Therefore, the final result is $ \\begin{bmatrix} 0 & 0 \\\\ 0 & \\frac{2}{x^2} \\end{bmatrix} $."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.5",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
